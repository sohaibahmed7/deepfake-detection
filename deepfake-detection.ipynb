{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b5d41d1",
   "metadata": {},
   "source": [
    "# COMPSCI 4AL3: Deepfake Detection Project (PyTorch)\n",
    "\n",
    "## Group 15\n",
    "\n",
    "This notebook provides the starting structure for our deepfake classification project using PyTorch.\n",
    "\n",
    "**Project Goal:** Build a model to classify images as \"Real\" or \"Fake\".\n",
    "\n",
    "**Our Plan:**\n",
    "1.  **Load Data:** Use `torchvision.transforms` and `ImageFolder` to load and preprocess the dataset.\n",
    "2.  **Define Model:** Use the `DeepfakeClassifier` class (subclassing `nn.Module`) to build our CNN architecture.\n",
    "3.  **Train Model:** Write a manual training and validation loop to train the model.\n",
    "4.  **Evaluate:** Test the final model on the unseen test set and report metrics (Accuracy, Precision, Recall, F1-score, Confusion Matrix)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfe672d",
   "metadata": {},
   "source": [
    "## 1. Setup: Import Libraries\n",
    "\n",
    "Import all necessary packages. We'll use `torch` and `torchvision` to build our CNN, `sklearn` for evaluation metrics, and `matplotlib` for plotting results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953ce963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "import copy\n",
    "\n",
    "# Scikit-learn for metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Set global parameters\n",
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SHAPE = (3, IMG_SIZE, IMG_SIZE) # PyTorch format: (Channels, Height, Width)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bd51d3",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing\n",
    "\n",
    "We define a `transform` pipeline to resize, crop, convert images to Tensors, and normalize them. Then, we use `ImageFolder` to load the pre-split data and `DataLoader` to create batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea71f01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! UPDATE THIS PATH !!!\n",
    "# Set the base directory where the 'Deepfake and Real Images' dataset is extracted\n",
    "DATA_DIR = Path(\"./kaggle/input/deepfake-and-real-images/\")\n",
    "\n",
    "# Define paths for each split\n",
    "train_dir = DATA_DIR / 'train'\n",
    "val_dir = DATA_DIR / 'validation'\n",
    "test_dir = DATA_DIR / 'test'\n",
    "\n",
    "# 1.2: Preprocessing/Feature Engineering step\n",
    "# Define transformations for the images\n",
    "# Normalization values are standard for models pre-trained on ImageNet\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        # TODO: Consider adding data augmentation here (e.g., RandomHorizontalFlip)\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Create datasets using ImageFolder\n",
    "    image_datasets = {\n",
    "        'train': datasets.ImageFolder(train_dir, data_transforms['train']),\n",
    "        'val': datasets.ImageFolder(val_dir, data_transforms['val']),\n",
    "        'test': datasets.ImageFolder(test_dir, data_transforms['test'])\n",
    "    }\n",
    "\n",
    "    # 2. Train/Test split is already done by the dataset structure\n",
    "    # Create DataLoaders\n",
    "    dataloaders = {\n",
    "        'train': DataLoader(image_datasets['train'], batch_size=BATCH_SIZE, shuffle=True, num_workers=4),\n",
    "        'val': DataLoader(image_datasets['val'], batch_size=BATCH_SIZE, shuffle=False, num_workers=4),\n",
    "        'test': DataLoader(image_datasets['test'], batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "    }\n",
    "\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "    CLASS_NAMES = image_datasets['train'].classes\n",
    "\n",
    "    print(f\"Class names found: {CLASS_NAMES}\")\n",
    "    print(f\"Dataset sizes: {dataset_sizes}\")\n",
    "\n",
    "    # Set device to GPU if available\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Dataset directory not found.\")\n",
    "    print(f\"Please make sure the dataset is at: {DATA_DIR}\")\n",
    "    print(\"You can download it from: https://www.kaggle.com/datasets/manjilkarki/deepfake-and-real-images/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714a89d1",
   "metadata": {},
   "source": [
    "## 3. Model Definition: The `DeepfakeClassifier` Class\n",
    "\n",
    "This class encapsulates our model's architecture by inheriting from `nn.Module`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bab6d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepfakeClassifier(nn.Module):\n",
    "    \"\"\"1. A class which represents the model/classifier.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"1.1: Initialize the model's layers.\"\"\"\n",
    "        super(DeepfakeClassifier, self).__init__()\n",
    "        \n",
    "        # --- START OF CNN ARCHITECTURE ---\n",
    "        # TODO: This is a basic placeholder. Iterate and improve this architecture.\n",
    "        \n",
    "        # Block 1: (3 x 128 x 128) -> (32 x 64 x 64)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Block 2: (32 x 64 x 64) -> (64 x 32 x 32)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Block 3: (64 x 32 x 32) -> (128 x 16 x 16)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # --- END OF CNN ARCHITECTURE ---\n",
    "        \n",
    "        # Flatten the 3D features to 1D vector\n",
    "        # Size will be 128 * 16 * 16 = 32768\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # Fully-connected layers\n",
    "        self.fc1 = nn.Linear(in_features=128 * 16 * 16, out_features=128)\n",
    "        # TODO: Consider adding Dropout layers\n",
    "        # self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        # Output layer: 1 node for binary classification\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Defines the forward pass of the data through the layers.\"\"\"\n",
    "        \n",
    "        # Pass through conv/pool blocks\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        # Flatten for the fully-connected layers\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        # Pass through dense layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # x = self.dropout(x) # Apply dropout if using\n",
    "        \n",
    "        # Output layer (no activation here, as nn.BCEWithLogitsLoss combines sigmoid + loss)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b658bc",
   "metadata": {},
   "source": [
    "## 4. Model Training\n",
    "\n",
    "First, we instantiate the model, optimizer, and loss function. Then, we create a function to handle the training and validation loops (1.3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1e60ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instantiate the model and move it to the device\n",
    "model = DeepfakeClassifier().to(device)\n",
    "\n",
    "# Optional: Print a summary of the model (requires torchinfo)\n",
    "# !pip install torchinfo\n",
    "# from torchinfo import summary\n",
    "# summary(model, input_size=(BATCH_SIZE, 3, IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "# 2. Define Loss Function and Optimizer\n",
    "# Use BCEWithLogitsLoss, which is numerically stable and includes the sigmoid activation\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Use the Adam optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# TODO: Consider a learning rate scheduler\n",
    "# exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1efab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=10):\n",
    "    \"\"\"1.3: Function for training and making predictions (validation).\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # To track history\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase (3. Validation)\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                # Labels need to be float and shape [batch_size, 1] for BCEWithLogitsLoss\n",
    "                labels = labels.float().view(-1, 1).to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                # Track history only if in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    # Get predictions (apply sigmoid and threshold)\n",
    "                    preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "\n",
    "                    # Backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            history[f'{phase}_loss'].append(epoch_loss)\n",
    "            history[f'{phase}_acc'].append(epoch_acc.item())\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Deep copy the model if it's the best one yet\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - start_time\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f6c4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Adjust the number of epochs as needed.\n",
    "EPOCHS = 15\n",
    "\n",
    "if 'dataloaders' in locals():\n",
    "    model, history = train_model(model, criterion, optimizer, num_epochs=EPOCHS)\n",
    "else:\n",
    "    print(\"Skipping training because data was not loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f3e3f5",
   "metadata": {},
   "source": [
    "## 5. Results and Evaluation\n",
    "\n",
    "Here we'll plot our training history and print the final classification metrics from the test set, as outlined in the proposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b308de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"4. Plots the model's training and validation accuracy/loss.\"\"\"\n",
    "    \n",
    "    # Convert tensor values to CPU numpy arrays if they aren't already\n",
    "    acc = [h for h in history['train_acc']]\n",
    "    val_acc = [h for h in history['val_acc']]\n",
    "    loss = [h for h in history['train_loss']]\n",
    "    val_loss = [h for h in history['val_loss']]\n",
    "\n",
    "    epochs_range = range(len(acc))\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()\n",
    "\n",
    "if 'history' in locals():\n",
    "    plot_training_history(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b63a99b",
   "metadata": {},
   "source": [
    "### 5.2. Final Evaluation on Test Set\n",
    "\n",
    "Now we use the unseen test set to get our final, unbiased metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580a55cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, data_loader):\n",
    "    \"\"\"1.3: Helper function to get predictions on the test set.\"\"\"\n",
    "    model.eval()   # Set model to evaluate mode\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad(): # Disable gradient calculation\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            # Get predictions (apply sigmoid and threshold)\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "    return np.array(all_labels), np.array(all_preds).flatten()\n",
    "\n",
    "\n",
    "if 'dataloaders' in locals() and 'model' in locals():\n",
    "    # 1. Get predictions and true labels\n",
    "    y_true, y_pred = get_predictions(model, dataloaders['test'])\n",
    "    \n",
    "    # 2. Print detailed classification report (Precision, Recall, F1-score)\n",
    "    print(\"\\n--- Classification Report ---\")\n",
    "    print(classification_report(y_true, y_pred, target_names=CLASS_NAMES))\n",
    "    \n",
    "    # 3. Plot Confusion Matrix\n",
    "    print(\"\\n--- Confusion Matrix ---\")\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=CLASS_NAMES)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Skipping evaluation because data or model is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbbb5bd",
   "metadata": {},
   "source": [
    "## 6. Next Steps\n",
    "\n",
    "Our goal is to achieve at least 60% accuracy.\n",
    "\n",
    "To improve this model, we should focus on:\n",
    "1.  **Iterating on `DeepfakeClassifier`:** \n",
    "    * Try adding more `nn.Conv2d` layers.\n",
    "    * Try different `out_channels` (e.g., 32, 64, 128, 256).\n",
    "    * Add `nn.Dropout(0.5)` layers after `F.relu` in the fully-connected part to reduce overfitting.\n",
    "2.  **Hyperparameter Tuning:**\n",
    "    * Try different optimizers (e.g., `optim.SGD`, `optim.RMSprop`).\n",
    "    * Try different learning rates (e.g., `lr=0.0001`).\n",
    "    * Add a learning rate scheduler (like `optim.lr_scheduler.StepLR`).\n",
    "    * Increase the number of `EPOCHS`.\n",
    "3.  **Feature Engineering:**\n",
    "    * Add data augmentation to the `data_transforms['train']` pipeline. For example:\n",
    "        * `transforms.RandomHorizontalFlip()`\n",
    "        * `transforms.RandomRotation(10)`\n",
    "        * `transforms.ColorJitter(brightness=0.2, contrast=0.2)`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
